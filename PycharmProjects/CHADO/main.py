import osimport loggingimport asynciofrom io import BytesIOfrom dotenv import load_dotenvfrom PIL import Imagefrom aiogram import Bot, Dispatcher, typesfrom aiogram.filters import Commandfrom aiogram.types import FSInputFileimport torchfrom diffusers import StableDiffusionControlNetPipeline, ControlNetModelfrom controlnet_aux import CannyDetector# ‚Äî‚Äî‚Äî –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Å—Ç–∞–Ω—Ç ‚Äî‚Äî‚Äîload_dotenv(".dev")TELEGRAM_TOKEN    = os.getenv("TELEGRAM_TOKEN")HF_TOKEN          = os.getenv("HUGGINGFACE_TOKEN", None)BASE_MODEL_ID     = os.getenv("BASE_MODEL_ID")CONTROLNET_ID     = os.getenv("CONTROLNET_MODEL_ID")DEVICE            = os.getenv("DEVICE", "cuda")COND_SCALE        = float(os.getenv("CONDITIONING_SCALE", 1.2))STRENGTH          = float(os.getenv("STRENGTH", 0.28))GUIDANCE_SCALE    = float(os.getenv("GUIDANCE_SCALE", 7.5))NUM_STEPS         = int(os.getenv("NUM_STEPS", 24))DEFAULT_PROMPT    = os.getenv("DEFAULT_PROMPT", "photorealistic, high quality")# ‚Äî‚Äî‚Äî –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ ‚Äî‚Äî‚Äîlogging.basicConfig(level=logging.INFO)logger = logging.getLogger(__name__)# ‚Äî‚Äî‚Äî –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–æ—Ç–∞ –∏ –¥–∏—Å–ø–µ—Ç—á–µ—Ä–∞ ‚Äî‚Äî‚Äîbot = Bot(token=TELEGRAM_TOKEN)dp  = Dispatcher()# ‚Äî‚Äî‚Äî –ó–∞–≥—Ä—É–∑–∫–∞ –ø–∞–π–ø–ª–∞–π–Ω–∞ Stable Diffusion + ControlNet ‚Äî‚Äî‚Äîdef init_pipeline():    token = HF_TOKEN or None    controlnet = ControlNetModel.from_pretrained(        CONTROLNET_ID,        torch_dtype=torch.float16,        use_auth_token=token    )    pipe = StableDiffusionControlNetPipeline.from_pretrained(        BASE_MODEL_ID,        controlnet=controlnet,        torch_dtype=torch.float16,        use_auth_token=token    ).to(DEVICE)    pipe.enable_xformers_memory_efficient_attention()    return pipepipe  = init_pipeline()canny = CannyDetector()# ‚Äî‚Äî‚Äî –•–µ–Ω–¥–ª–µ—Ä—ã ‚Äî‚Äî‚Äî@dp.message(Command(commands=["start"]))async def cmd_start(message: types.Message):    await message.answer(        "üëã –ü—Ä–∏—à–ª–∏—Ç–µ –º–Ω–µ —Ä–µ–Ω–¥–µ—Ä/—Ñ–æ—Ç–æ ‚Äî\n"        "—è –≤–µ—Ä–Ω—É –µ–≥–æ —Å —Ñ–æ—Ç–æ—Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π, —Å–æ—Ö—Ä–∞–Ω—è—è –≥–µ–æ–º–µ—Ç—Ä–∏—é."    )@dp.message(types.ContentType.PHOTO)async def photo_handler(message: types.Message):    # 1) –°–æ–∑–¥–∞—ë–º —Å–æ–æ–±—â–µ–Ω–∏–µ-—Å—Ç–∞—Ç—É—Å    status_msg = await message.answer("üîÑ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é‚Ä¶ 0%")    cd / Users / kostakovacev / PycharmProjects / CHADO    # 2) –°–∫–∞—á–∏–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–∑ Telegram    file_path = (await message.photo[-1].download()).name    img = Image.open(file_path).convert("RGB")    # 3) –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∫–∞—Ä—Ç—É Canny    control_map = canny(img)    # 4) –ì–æ—Ç–æ–≤–∏–º callback –¥–ª—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞    loop = asyncio.get_event_loop()    def progress_callback(step: int, timestep, latents):        pct = int((step + 1) * 100 / NUM_STEPS)        loop.create_task(            status_msg.edit_text(f"üîÑ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é‚Ä¶ {pct}%")        )    # 5) –ó–∞–ø—É—Å–∫–∞–µ–º –ø–∞–π–ø–ª–∞–π–Ω —Å ControlNet    output = pipe(        prompt=DEFAULT_PROMPT,        image=img,        control_image=control_map,        controlnet_conditioning_scale=COND_SCALE,        strength=STRENGTH,        num_inference_steps=NUM_STEPS,        guidance_scale=GUIDANCE_SCALE,        callback=progress_callback,        callback_steps=1,    ).images[0]    # 6) –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –±–∞–π—Ç—ã –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º    bio = BytesIO()    output.save(bio, format="PNG")    bio.seek(0)    await message.reply_photo(photo=bio)    # 7) –§–∏–Ω–∞–ª—å–Ω—ã–π –∞–ø–¥–µ–π—Ç —Å—Ç–∞—Ç—É—Å–∞    await status_msg.edit_text("‚úÖ –ì–æ—Ç–æ–≤–æ!")# ‚Äî‚Äî‚Äî –ó–∞–ø—É—Å–∫ –±–æ—Ç–∞ ‚Äî‚Äî‚Äîif __name__ == "__main__":    logger.info("–ë–æ—Ç –∑–∞–ø—É—â–µ–Ω...")    asyncio.run(dp.start_polling(bot))